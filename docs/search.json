[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "remote sensing learning diary",
    "section": "",
    "text": "Preface\nThis is a Quarto book. To learn more about Quarto books visit https://quarto.org/docs/books.\n\n\nIntroduction\nHi there! I’m Viktoria. On the following pages you’ll find my learning diary for the module Remote Sensing, which is part of the MSc Urban Spatial Science at the CASA, the Centre for Advanced Spatial Analysis at the University College London. For each week, you’ll find a short summary of the concepts covered that week, some examples of how they are applied and some personal reflections.\nI am a part time student. When I’m not studying, I work as an urban planner in the international development sector. I have been working in this field for the past 5 years in different roles - as an urban development consultant for a multidisciplinary built environment consultancy (Atkins) and as a policy advisor to the Ministry for International Development in Germany. Over the years, I worked on the design and implementation of urban development projects and programmes, mainly linked to climate change and urban resilience as well as reconstruction in a range of cities in Low and Middle Income Countries, including Gyumri in Armenia, Kharkiv in Ukraine, Rasjahi in Bangladesh, Mandera in Kenya, Alexandria in Egypt.\nFrom my experience, a key challenge in these projects is a lack of reliable data on the urban systems that can serve as a baseline for policy making and investment planning. This challenge is particularly acute in small cities in Africa and Asia, where the majority of urbanisation is predicted to take place in the future.\nI am studying the remote sensing module because I believe that remote sensing and earth observation have great potential for closing this data gap and thereby improving urban planning, policy and investment decisions, especially in Low and Middle Income Countries. Within this industry, there seems to be a lot of excitement around the potential of this technology but very few people who can actually do the analysis or run programmes, where such analysis is done. I want to become one of the people who can help putting remote sensing into practice and make it work for the international development and humanitarian sector.\nTherefore, i will relate the content covered in this module to places and topics that are relevant within this sector. Some of the issues, I find interesting include:\n\ndetect informal urban growth to better plan for informal settlements,\nmonitor conflict and assess damage as a baseline for reconstruction processes, and\nanalyse climate change related risks in cities, especially heat, drought and flooding.",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "intro.html",
    "href": "intro.html",
    "title": "3  Introduction",
    "section": "",
    "text": "This is a book created from markdown and executable code.\nSee (knuth84?) for additional discussion of literate programming.\n\n1 + 1\n\n[1] 2",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "summary.html",
    "href": "summary.html",
    "title": "4  Summary",
    "section": "",
    "text": "In summary, this book has no content whatsoever.\n\n1 + 1\n\n[1] 2",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Summary</span>"
    ]
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Aimaiti, Yusupujiang, Christina Sanon, Magaly Koch, Laurie G. Baise, and\nBabak Moaveni. 2022. “War Related Building Damage\nAssessment in Kyiv, Ukraine,\nUsing Sentinel-1 Radar and Sentinel-2 Optical\nImages.” Remote Sensing 14 (24): 6239. https://doi.org/10.3390/rs14246239.\n\n\nAlex De Waal. 2017. Mass Starvation: The History and\nFuture of Famine. John Wiley & Sons.\n\n\nBrady, Maria. 2021. “Remote Sensing for Dummies.”\nArcGIS StoryMaps. May 11, 2021. https://storymaps.arcgis.com/stories/cb1577b0f5bc485c974b4ea19d52282d.\n\n\nGorelick, Noel, Matt Hancher, Mike Dixon, Simon Ilyushchenko, David\nThau, and Rebecca Moore. 2017. “Google Earth Engine:\nPlanetary-scale Geospatial Analysis for\nEveryone.” Remote Sensing of Environment 202 (December):\n18–27. https://doi.org/10.1016/j.rse.2017.06.031.\n\n\nHa, Minh, Phuong Vu, Huu Nguyen, Tich Hoang, Dinh Dang, Thi Dinh,\nGheorghe Şerban, Ioan Rus, and Petre Brețcan. 2022. “Machine\nLearning and Remote Sensing Application for\nExtreme Climate Evaluation: Example of\nFlood Susceptibility in the Hue Province,\nCentral Vietnam Region.” Water 14 (10):\n1617. https://doi.org/10.3390/w14101617.\n\n\nJeffrey A. Cardille, Nick Clinton, Morgan Crowley, and David Saah. n.d.\nCloud-Based Remote Sensing with Google Earth\nEngine. https://www.eefabook.org/about.html.\n\n\nKhan, Ramla, and Hammad Gilani. 2021. “Global Drought Monitoring\nwith Drought Severity Index (DSI) Using Google Earth\nEngine.” Theoretical and Applied Climatology 146\n(1-2): 411–27. https://doi.org/10.1007/s00704-021-03715-9.\n\n\nMatarira, Dadirai, Onisimo Mutanga, and Maheshvari Naidu. 2022.\n“Google Earth Engine for Informal Settlement\nMapping: A Random Forest Classification Using\nSpectral and Textural Information.”\nRemote Sensing 14 (20, 20): 5130. https://doi.org/10.3390/rs14205130.\n\n\nMehmood, Hamid, Crystal Conway, and Duminda Perera. 2021. “Mapping\nof Flood Areas Using Landsat with Google Earth Engine\nCloud Platform.” Atmosphere 12 (7, 7): 866. https://doi.org/10.3390/atmos12070866.\n\n\n“Monitoring War Destruction from Space Using Machine\nLearning.” n.d. Accessed March 9, 2024. https://doi.org/10.1073/pnas.2025400118.\n\n\nPrakash, Mihir, Steven Ramage, Argyro Kavvada, and Seth Goodman. 2020.\n“Open Earth Observations for Sustainable Urban\nDevelopment.” Remote Sensing 12 (10, 10): 1646.\nhttps://doi.org/10.3390/rs12101646.\n\n\nTwumasi, Yaw A., Edmund C. Merem, John B. Namwamba, Abena B.\nAsare-Ansah, Jacob B. Annan, Zhu H. Ning, Rechael N. D. Armah, et al.\n2022. “Flood Mapping in Mozambique Using\nCopernicus Sentinel-2 Satellite Data.” Advances in\nRemote Sensing 11 (03): 80–105. https://doi.org/10.4236/ars.2022.113006.\n\n\n“Using Open Data to Detect the Structure and Pattern of Informal\nSettlements: An Outset to Support Inclusive SDGs’\nAchievement.” n.d. Accessed February 7, 2024. https://www.tandfonline.com/doi/epdf/10.1080/20964471.2021.1948178?needAccess=true.",
    "crumbs": [
      "References"
    ]
  },
  {
    "objectID": "week1.html",
    "href": "week1.html",
    "title": "1  Getting started with Remote Sensing",
    "section": "",
    "text": "1.1 Summary\nThis week, I am covering the basics of what remote sensing is and will focus on how remote sensing is based on the electromagnetic field. Other topics this week included scattering, interaction with the earth surface, data formats, and resolution.\nRemote Sensing, also referred to as Earth Observation, is the process of collecting information about the Earth’s surface from a distance. The information is obtained through aerial photography by airplanes or drones, or from satellite images. The foundation of Remote Sensing the electromagnetic radiation or more simply put light reflected from objects. Brady (2021)\nThe Electro Magnetic Spectrum (EMS) has a huge range of energy waves, electric or magnetic, that vary in amplitude (α), length (λ), and frequency Brady (2021). Only a fraction of the spectrum is visible to the human eye. Those that are visible, we see as colors. All objects on the earth reflect electromagnetic waves in unique ways. For exmaple, trees have a different electromagnetic signature than buildings or water bodies.\nThe images taken through remote sensing include wavelengths beyond those that are visible to the human eye. Therefore, analysis of this information allows us to see much more than what would be possible to see on e.g., a simple photography. Sections on the electric magnetic spectrum are captured in so called “bands”. The more bands, the higher the spectral resolution of the image.\nGenerally, there are two types of sensors – active and passive ones. Passive sensors use the sun as their energy source, while active sensors have their own energy source and therefore emit electromagnetic waves (Slides).\nknitr::include_graphics('figures/w1p1.png')\n\n\n\n\nFigure 1: Electric and magnetic waves in the electromagnetic field\nknitr::include_graphics('figures/w1p2.png')\n\n\n\n\nFigure 2: Amplitude, length, and frequency of electric wave",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Getting started with Remote Sensing</span>"
    ]
  },
  {
    "objectID": "week1.html#application",
    "href": "week1.html#application",
    "title": "1  Getting started with Remote Sensing",
    "section": "1.2 Application",
    "text": "1.2 Application\nAs for many other technologies, remote sensing has its origin in the military and defense sector. It was first invented to gather information about the enemy in war, e.g. troop deployment or battle territory Brady (2021). While still used in this sector, today remote sensing has been adopted in a range of other disciplines including:\n\nClimate science e.g., measuring changes in temperature over time,\nDisaster Risk Reduction and Management, e.g., mapping flood risks,\nEnvironmental science e.g., measuring water quality,\nGeology e.g., measuring volcanic activity,\nUrban Planning e.g., identifying informal settlements and monitoring urban growth,\nConflict studies e.g., measuring destruction in battle\n\nBelow I discuss the use of Sentinel and Landsat data in the field of disaster risk reduction, more specifically flood risk management. Both Landsat and Sentinel data are being used for flood mapping.\n\n1.2.1 Approach to Mapping Flood Areas using Landsat\nFigure 3 provides an overview of a typical work flow for a flood risk mapping using Landsat Data. We will understand these steps better over the coming weeks. In short, Landsat 5, 7, and 8 images with low cloud cover are used to cover a longer period. A classifier that differentiates permanent water from temporary water (flood) is applied and vegetation and site specific other data (HAND) is masked (cut out) to leavev only a map of permanent and temporary water.The authors discuss that the accuracy of the classifier could be improved by training it on sentinel data. I think this may be due to the fact that sentinel data has a higher resolution (10m) than Landsat (30m).They also state that this map does not consider socio-demographic data to understand vulnerability. Mehmood, Conway, and Perera (2021)\n\nknitr::include_graphics('figures/w1f4.png')\n\n\n\n\nFigure 3: Workflow Flood Mapping\n\n\n\n\n\n\n1.2.2 Flood Mapping in Mozambique using Copernicus Sentinel-2 Satellite Data\nTwumasi et al. (2022), do just that. They mapped inundation caused by tropical cyclones in Maputo and Beira using Sentinel 2 data and combined they findings with demographic data to understand the impact of these floods on people.\nSome of the image processing methods applied sound already somewhat familiar as we covered them in the lecture: “The images were geometrically corrected to remove, haze, scan lines and speckles, and then referenced to Mozambique ground-based Geographic: Lat/Lon coordinate system and WGS 84 Datum. Data from twelve spectral bands of Sentinel-2 satellite, covering the visible and near infrared sections of the electromagnetic spectrum, were further used in the analysis.” Twumasi et al. (2022)\nSomething that I noticed is that the study only takes into account the growing population for forecasting but not the effects of climate change on the likelihood and intensity of tropical cyclones in the future.\n\nknitr::include_graphics('figures/w1p3.png')\n\n\n\n\nFigure 4: Senitnel 2 image of Mosampique flooding including in Maputo",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Getting started with Remote Sensing</span>"
    ]
  },
  {
    "objectID": "week1.html#reflection",
    "href": "week1.html#reflection",
    "title": "1  Getting started with Remote Sensing",
    "section": "1.3 Reflection",
    "text": "1.3 Reflection\nNext to learning about the electromagnetic field (something I hadn’t really thought about since 8th grade physics lessons) an issue that was interesting to me this week, was the range of different satellites available delivering imagery at different quality and cost.\nIn my work in the international development sector, we are often constraint to using publicly available data. This is due to tight project budgets but also because work done by external consultants should be reproducible by the beneficiary themselves, e.g. a local government. I wonder to what extend this presents a barrier for using remote sensing in the development and humanitarian sector. In fact, it seems that many of the free resources of satellite images provide good enough resolution for many planning and policy decisions. The International Monetary Fund for example, already considered remote sensing as a low cost option for data collection in comparison to airborne or ground surveys in 1992. (bhattSateEteRemoteSensing1992?) Today, there is much more satellite images available and analysis has become easier, using applications like Google Earth Engine.\nEven though remote sensing is a low cost option for data collection, it is not yet applied yet in large scale in the area I work in (urban planning & international development). According to a recent paper on the potential of remote sensing for the urban development sector, this may be due to limited capabilities in local governments and reluctance to change existing data collection and management systems. Prakash et al. (2020)\n\n\n\n\nBrady, Maria. 2021. “Remote Sensing for Dummies.” ArcGIS StoryMaps. May 11, 2021. https://storymaps.arcgis.com/stories/cb1577b0f5bc485c974b4ea19d52282d.\n\n\nMehmood, Hamid, Crystal Conway, and Duminda Perera. 2021. “Mapping of Flood Areas Using Landsat with Google Earth Engine Cloud Platform.” Atmosphere 12 (7, 7): 866. https://doi.org/10.3390/atmos12070866.\n\n\nPrakash, Mihir, Steven Ramage, Argyro Kavvada, and Seth Goodman. 2020. “Open Earth Observations for Sustainable Urban Development.” Remote Sensing 12 (10, 10): 1646. https://doi.org/10.3390/rs12101646.\n\n\nTwumasi, Yaw A., Edmund C. Merem, John B. Namwamba, Abena B. Asare-Ansah, Jacob B. Annan, Zhu H. Ning, Rechael N. D. Armah, et al. 2022. “Flood Mapping in Mozambique Using Copernicus Sentinel-2 Satellite Data.” Advances in Remote Sensing 11 (03): 80–105. https://doi.org/10.4236/ars.2022.113006.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Getting started with Remote Sensing</span>"
    ]
  },
  {
    "objectID": "introduction.html",
    "href": "introduction.html",
    "title": "1  Introduction",
    "section": "",
    "text": "Hi there! I’m Viktoria. On the following pages you’ll find my learning diary for the module Remote Sensing, which is part of the MSc Urban Spatial Science at the CASA, the Centre for Advanced Spatial Analysis at the University College London. For each week, you’ll find a short summary of the concepts covered that week, some examples of how they are applied and some personal reflections.\nI am a part time student. When I’m not studying, I work as an urban planner in the international development sector. I have been working in this field for the past 5 years in different roles - as an urban development consultant for a multidisciplinary built environment consultancy (Atkins) and as a policy advisor to the Ministry for International Development in Germany. Over the years, I worked on the design and implementation of urban development projects and programmes, mainly linked to climate change and urban resilience as well as reconstruction in a range of cities in Low and Middle Income countries, including Gyumri in Armenia, Kharkiv in Ukraine, Rasjahi in Bangladesh, Mandera in Kenya, Alexandria in Egypt.\nFrom my experience, a key challenge in these projects is a lack of reliable data on the urban systems that can serve as a baseline for policy making and investment planning. This challenge is particularly acute in small cities in Africa and Asia, where the majority of urbanisation is predicted to take place in the future.\nI am studying the remote sensing module because I believe that remote sensing and earth observation have great potential for closing this data gap and thereby improving urban planning, policy and investment decisions, especially in Low and Middle Income Countries. Within this industry, there seems to be a lot of talk around the potential of this technology but very few people who can actually do the analysis or run programmes where such analysis is done. I want to become one of the people who can put remote sensing into practice and make it work for the international development and humanitarian sector.\nTherefore, i will relate the content covered in this module places and topics that are relevant within this sector. Some of the issues, I find interesting include:\n\nmonitor informal urban growth to better plan for informal settlements,\nmonitoring conflict and assess damage as a baseline for reconstruction processes,\nmeasuring drought to prevent famine,\nunderstand climate change related risks in cities, especially heat and flooding.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "week2.html",
    "href": "week2.html",
    "title": "2  Xaringan Presentation and Quarto Book",
    "section": "",
    "text": "This week is a little different and does not follow the usual structure of summary, application and reflection. We looked at the tools to make presentations and websites with code. For presentations, we can use Xaringan and for Books/Websites Quarto. This website is made with Quarto in R Studio and I set it up during week 2. Below you’ll find a short presentation on Sentinel-2, which i made using Xaringan.\n\nReflective note on making this presentation: It took me a while to get started with Xaringan. Once I got the hang of it, I loved how easy it is to change the style of the presentation. It also seems to be a great tool to make your presentations look more streamlined. However, tbh, ppt is also really good at that and most people can use it. If you work in teams of coders and non-coders (which is most often the case in urban planning projects), it’s not helpful to use tools that are not easily accessible to non coders.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Xaringan Presentation and Quarto Book</span>"
    ]
  },
  {
    "objectID": "week3.html",
    "href": "week3.html",
    "title": "3  Remote Sensing Data & Corrections",
    "section": "",
    "text": "3.1 Summary\nThis week had a lot of very technical content around the concepts of corrections, merging images and enhancement. Honestly, a bit overwhelming at first. The good news is that a lot of the methods covered this week are automated, when using tools like Google Earth Engine. Therefore, for me it is important to understand the broad concepts rather than how each method is exactly implemented. To this end, the table below provides short explanations for some of the concepts of this week. I used the lecture slides, the practical content, Michael Hathorn’s Learning Diary, and Chat GPT to compile this table.\nWarning: package 'kableExtra' was built under R version 4.3.2\n\n\n\n\n\n\nTerm\nDescription\n\n\n\n\nGeometric Correction\nRemote sensing data often has image distortion issues due to the angle its taken from (e.g., off-nadir means not directly down), the topography, or the rotation of the earth. This can be fixed by taking Ground Control Points (GPS) and matching them with known points in the image and a reference dataset (goldstandard, where we know its corrrect) using different algorithms.\n\n\nAtmospheric Correction\nAbsorption and scattering create atmospheric haze and makes pixels bleed into one another. It makes the image less clear (less contrast). There are two sources of environmental attenuation: Atmospheric scattering and topographic attenuation.\n\n\nOrthorectification Correction\nGeorectification means giving coordinates to an image. Orthorectification means removing distortions by making the pixels viewed at nadir.\n\n\nDark Object Subtraction (DOS)\nMethod to correct for atmospheric effects and sensor-specific artifacts. In DOS, the darkest objects in an image, such as shadows or non-reflective surfaces, are identified and assumed to represent the true \"dark\" or background signal. The pixel values of these dark objects are then subtracted from the entire image, effectively normalizing the data and reducing atmospheric influence. DOS helps enhance the contrast and accuracy of satellite imagery, particularly in areas with varying atmospheric conditions or topography.\n\n\nDigital Number (DN)\nThe raw number that the sensor stores, or the value that the sensor \"sees\" (no unit).\n\n\nRadiance\nRadiance is derived from DN. DN to spectral radiance = radiometric calibration. It refers to the electromagnetic radiation emitted or reflected from the Earth's surface and recorded by the sensors/satellites (e.g., light reflected from a tree). It represents the intensity of radiation across different wavelengths or spectral bands. Is used as a measurement for understanding different materials on the earth surface (e.g., vegitation). Also called Top Of the Atmosphere Reflectance.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Remote Sensing Data & Corrections</span>"
    ]
  },
  {
    "objectID": "week3.html#application",
    "href": "week3.html#application",
    "title": "3  Remote Sensing Data & Corrections",
    "section": "3.2 Application",
    "text": "3.2 Application\nThis week was very concept heavy. I decided to use this week and next to engage with an application area of remote sensing that I have always been interested in: mapping informal settlements in cities. I wanted to see if I come across some of the concepts described above, reading through the studies.\nInformal settlements are often the most vulnerable parts of cities. They tend to be located in areas that are extremely vulnerable to the effects of climate change, such as flooding or heat and lack basic urban services, such as sanitation infrastructure or public transport. Makeshift houses leave residents exposed to the elements, and provide little protection against intruders. Many people living in informal settlements lack security of tenure and are under constant threat of eviction. What may look like temporary neighborhoods often remain for decades. One of the most famous examples, is Dharavi in Mumbai. Dharavi is one of the largest slums in the world right in the center of Mumbai (Figure 3).\n\nknitr::include_graphics('figures/w3p1a.png')\n\n\n\n\nFigure 5:Darawi\n\n\n\n\nI looked into a few studies that use remote sensing to map informal settlements and turns out its “a mammoth task due to the spatial heterogeneity of urban landscape components, requiring complex analytically processes.” Matarira, Mutanga, and Naidu (2022)\nIt seems that many studies use Very High Resolution (VHR) and High Resolution (HR) satellite imagery. Such data sets are expensive and therefore not accessible for local governments, especially in low and middle income countries, where most slums are. “Using Open Data to Detect the Structure and Pattern of Informal Settlements: An Outset to Support Inclusive SDGs’ Achievement” (n.d.) More recently, researchers tried to find methods to work with openly available data sets such as Sentinel or Landsat to identify informal settlements.\nI looked more closely at a study conducted in Durban South Africa. Matarira, Mutanga, and Naidu (2022) The paper investigates different data input combinations in order to find the one that presents most accurate and reliable findings.The study uses Google Earth Engine to process Sentinel 2 images of the city of Durban integrating spectral and textural features in order to understand the extent and location of informal settlements. The study found that a classification based on spectral bands and textural information has the highest accuracy. It was able to detect informal settlements with a 80% accuracy.\nThe method used was pretty complex and I didn’t understand it fully. I still summarized the key steps below, which I found useful as it gave me a rough understanding of the workflow and effort of such an analysis. Broad steps of the method listed below:\n\n3 images were selected to form a composite, and a median value was assigned to each pixel, resulting in a single image used for processing.\nExtraction of spectral and texture features from Sentinel 2A bands,\nEstablishing different combinations of these feature types to be tested,\nRandom Forest Classification using GEE,\nAssessment of the classifer’s accuracy (20 classification results were obtained for each input feature set),\nPerformance evaluation of feature subsets through a comparison of classification results of different feature subsets against the original feature set from which they were derived in order to establish if feature reduction would significantly improve informal settlement identification or not.\nAccuracy assessment to develop the relative comparative performances of different feature sets, against the benchmark experiment and was tested using Pixel-Based Accuracy Assessment and patch based.\nRegression between Extracted Informal Settlement Areas and Ground Truth Data.\n\nIt is great that the data used in this study is free. However, it still does not seem very accessible to a local government in a LMIC because technical capabilities to procure, let alone conduct such a study seems immense. It would be great if there was a spatial application that allowed city governments to map slums in their city in an automated way or at least with less technical requirements. Ollie Ballinger actually managed to built an interesting Google Earth Engine Application to map slums in Dar es Salam in Tansania. It is different to the approach taken in Durban because he remove the formal buildings and than applies classification only on the remaining areas. (Figure 4)\nhttps://www.iadb.org/en/who-we-are/topics/urban-development-and-housing/maiia\n\nknitr::include_graphics('figures/w3p2.png')\n\n\n\n\nFigure 6: Informal Settlement Mapper\n\n\n\n\n```",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Remote Sensing Data & Corrections</span>"
    ]
  },
  {
    "objectID": "week3.html#reflection",
    "href": "week3.html#reflection",
    "title": "3  Remote Sensing Data & Corrections",
    "section": "3.3 Reflection",
    "text": "3.3 Reflection\nThis week was a little painful, both for me (difficult concepts) and my laptop (computational power needed for working with remote sensing data).It got me excited to get started on Google Earth Engine, where a lot of these processes are automated and run on a cloud. It sounds like that makes it easier to focus on the analysis and get to the fun and interesting bits more quickly, rather than spending a long time making corrections and enhancements to the data. Thank you Google…\nI was not aware how difficult it is to map informal settlements with remote sensing data. I actually assumed it would be one of the easier methods as it is so well known. I can’t say that I completely understood the method used in Durban. However, it was still a worth wile exercise for me because it gave me a better idea of the workflow for remote sensing. It seems to be roughly: - Choose and download the images, - Make a composite, - Make corrections on it, - Identify the relevant features (spectral and texture), - Classification, - Validating and testing accuracy of classification, - Spatial analysis (e.g. regression).\n\n\n\n\nMatarira, Dadirai, Onisimo Mutanga, and Maheshvari Naidu. 2022. “Google Earth Engine for Informal Settlement Mapping: A Random Forest Classification Using Spectral and Textural Information.” Remote Sensing 14 (20, 20): 5130. https://doi.org/10.3390/rs14205130.\n\n\n“Using Open Data to Detect the Structure and Pattern of Informal Settlements: An Outset to Support Inclusive SDGs’ Achievement.” n.d. Accessed February 7, 2024. https://www.tandfonline.com/doi/epdf/10.1080/20964471.2021.1948178?needAccess=true.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Remote Sensing Data & Corrections</span>"
    ]
  },
  {
    "objectID": "week3.html#nonetheless-for-me-the-key-takeaways-from-this-week-are",
    "href": "week3.html#nonetheless-for-me-the-key-takeaways-from-this-week-are",
    "title": "3  Remote Sensing Data & Corrections",
    "section": "3.4 Nonetheless, for me, the key takeaways from this week are:",
    "text": "3.4 Nonetheless, for me, the key takeaways from this week are:\n\nB",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Remote Sensing Data & Corrections</span>"
    ]
  },
  {
    "objectID": "week4.html",
    "href": "week4.html",
    "title": "4  Policy",
    "section": "",
    "text": "4.1 Summary\nRasjahi is one of the major urban centers in Bangladesh with a population of around 500,000 people. It is located in the west of the country on the Indian-Bangladesh border and part of the Barind Tract, an area that experiences hot and dry climate. The most pressing climate challenges in the city are flooding during the monsoon season due to a poorly designed and maintained drainage system as well as extreme and dangerous heat.\nAccording to the Word Health Organisation, heatwaves are among the deadliest climate risk globally. In fact, more than 166,000 people died due to extreme temperatures between 1998-2017 (https://www.who.int/health-topics/heatwaves#tab=tab_3). In cities heat stress can be exacerbated due to so called urban heat island effects (UHI). UHI is a phenomenon where urban areas experience higher temperatures compared to their surrounding rural areas due to human activities and the way the city is built (e.g. heat retention in buildings, infrastructure, sealed surfaces). With climate change temperatures in Bangladesh are expected to increase and extreme weather events, such as heat waves, are expected to become more frequent and more intense.\nAt the national level, the Government of Bangladesh has acknowledged the risk posed by increasing heat. In its National Adaptation Plan from 2023 (NAP), heat features as an adaptation priority for urban areas. One of the action items in the urban area strategy of the NAP is to develop “heatwave and disease outbreak advisory services for city dwellers”. No further guidance on how to tackle heat in cities is given and it is up to the local level governments to improve heat risk planning. City budgets in Bangladesh tend to be very small, mainly dependent on national government funding transfers. It is often Multilateral Development Banks or donors, who finance urban plans or strategies, as part of the preparation of larger loan programs.\nAt the local level in Rajshahi, the City Cooperation has understood the importance of including climate change related hazards, including heat, into urban management. In recent years they have developed three important plans:\nThe ICLEI CAP provides a high level climate risk assessment. It describes UHI as an issue in the city but not spatially. Therefore, suggested mitigation and adaptation actions on heat remain vague.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Policy</span>"
    ]
  },
  {
    "objectID": "week4.html#summary",
    "href": "week4.html#summary",
    "title": "4  Policy",
    "section": "",
    "text": "A Masterplan that incorporate climate change issues (not publicly available, therefore will not discuss further),\nThe city government worked with ICLEI to develop a Climate Resilient Action Plan (CAP), and with\nthe Red Cross Climate Center to develop a heat threshold assessment for Rajshahi.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Policy</span>"
    ]
  },
  {
    "objectID": "week4.html#application",
    "href": "week4.html#application",
    "title": "4  Policy",
    "section": "4.2 Application",
    "text": "4.2 Application\nThe Red Cross Climate Center study expands ICLEI’s work by looking more closely at urban heat in the city and mapping it spatially. The authors used Landsat images between 2010 to 2020 to map Land Surface Temperature in the city to identify heat hot spots and Normalised difference water index (NDWI) and normalized difference vegetation index (NDVI) to analyse the relationship between land-cover changes and urban heat island effect (UHI). The findings are combined with demographic and socioeconomic data to understand vulnerability. However, the demographic and socioeconomic data sets from the national census are only available by ward. To develop specific actions for mitigating and adapting to the identified hotpots, we need data on the neighborhood, street and building level. The study presents some high level policy options for mitigation, including increasing green space, housing retrofit and street design.\nRemote sensing data could be used to improve the existing heat vulnerability assessment by identifying specific neighborhoods with poor housing conditions, such as slums, where residents are at higher risk of extreme indoor heat. This would take the Red Cross Climate Center to the next level.\nIt is likely that Rajshahi does not have high resolution remote sensing data, such a LiDAR data. Therefore, it is important to rely on publicly available data to ensure that the local government could reproduce the study. As demonstrated in a study conducted in Jakarta, Landsat 8, data can be used to identify informal settlements, despite lower resolution. A similar approach could be taken here. “Using Open Data to Detect the Structure and Pattern of Informal Settlements: An Outset to Support Inclusive SDGs’ Achievement” (n.d.)\nSeveral recent (e.g. from 2023) cloud-free images of the city should be obtained with a resolution of 30m. The relevant bands include: band 1-coastal aerosol, band 2-blue, band 3-green, band 4-red, band 5-near infrared (NIR), and bands 6 & 7-shortwave infrared (SWIR). The classification of land cover types could be done using Random Forest (RF) classifier combined available survey data of the city’s informal settlements and Open Street Map data. If no survey data exists, the local government could identify known informal areas that can be manually identified on the image and used for training the classifier. The sample should cover approximately 0.25% of the total study area to reach high accuracy. “Using Open Data to Detect the Structure and Pattern of Informal Settlements: An Outset to Support Inclusive SDGs’ Achievement” (n.d.)",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Policy</span>"
    ]
  },
  {
    "objectID": "week4.html#reflection",
    "href": "week4.html#reflection",
    "title": "4  Policy",
    "section": "4.3 Reflection",
    "text": "4.3 Reflection\nThe identified neighborhoods could be prioritized in investment planning. Incremental upgrading of buildings to reduce indoor temperature or planting of trees in most vulnerable areas could be possible policy options to battle heat stress in an equitable manner, where those most vulnerable are prioritized to achieve more equal living standards across the city.\nIt is very important to understand vulnerability spatially to take robust planning decisions. Many planning documents, including climate action plans, lack specification in terms of location of specific measures. The ICLEI Climate Action Plan for Rajshahi, for example, suggests increasing green space, but does not specify where. Could include Medellin example.\nThe goal of planning decisions is usually to maximize the benefit of an investment while minimizing costs (cost benefit analysis). The next step after identifying where informal settlements are would be to understand benefits of specific interventions, e.g. by modelling the effects of tree planting in different locations.\n\n\n\n\n“Using Open Data to Detect the Structure and Pattern of Informal Settlements: An Outset to Support Inclusive SDGs’ Achievement.” n.d. Accessed February 7, 2024. https://www.tandfonline.com/doi/epdf/10.1080/20964471.2021.1948178?needAccess=true.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Policy</span>"
    ]
  },
  {
    "objectID": "week5.html",
    "href": "week5.html",
    "title": "5  An Introduction to Google Earth Engine",
    "section": "",
    "text": "5.1 Summary\nThis week, we finally started working with Google Earth Engine (GEE). I was excited about this because it is supposed to allow researchers and practitioners to cut straight to the interesting analytically steps of the work flow and make the downloading and (pre-) processing of the satellite data easier and faster. Great news for someone like me who is still a newbie to the whole coding and data science world.\nIn summary, GEE is a cloud-based platform developed by Google that enables users to access and analyse huge amounts of satellite data. The main advantage is that, when we do analysis on GEE it’s not running on our own machine. It is either running on the browser (client side) or on Google serves (server side). The GGE servers are very powerful and can compute huge amounts of data in seconds.\nknitr::include_graphics('figures/w5p1.png')\n\n\n\n\nFigure 8: Google Earth Engine User Interface\nAnother great thing about GEE is its data catalog where a wide range of satellite data sets are stored. For example, it holds the entire Landsat Catalog. From the Catalog, data can be loaded directly into our project and the catalog even gives you the code to do so.\nAn Application Programming Interface (API) is a set of rules and tools that allows different software applications to talk to each other and share information or functionality. It’s like the language we need to speak, so that a certain software can understand what we want. The GEE API supports Python and Java Script. However, Java Script was the first language used for GEE and therefore there is much more documentation for it. First, I was a little annoyed when I heard that next to Python, R, and SQL, I needed to learn yet another language. But turns out, the Java Script you need to know to use GEE is fairly simple. The main differences between Java script and R are:\nGEE allows very fast visualization during algorithm development as it deploys a pyramid of reduced resolution. This is a hierarchical structure of image tiles generated from original high-resolution imagery. This pyramid is created by systematically down scaling the resolution of the original images, producing a series of progressively lower-resolution versions. Each level of the pyramid represents a different level of detail, with the top level typically being the highest resolution and subsequent levels having progressively lower resolutions. This makes storages and retrieving images more efficient and also allows us to zoom in and out on the map and the resolution of pixels adjusting accordingly.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>An Introduction to Google Earth Engine</span>"
    ]
  },
  {
    "objectID": "week5.html#summary",
    "href": "week5.html#summary",
    "title": "5  An Introduction to Google Earth Engine",
    "section": "",
    "text": "Variables (or objects) as defined with var..\nA specific part of your code ends with a ;\nObjects are dictionaries in Javascript.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>An Introduction to Google Earth Engine</span>"
    ]
  },
  {
    "objectID": "week5.html#application",
    "href": "week5.html#application",
    "title": "5  An Introduction to Google Earth Engine",
    "section": "5.2 Application",
    "text": "5.2 Application\nIn this week’s practical we calculated NDVI using Google Earth Engine. NDVI stands “normalized difference vegetation index” and it is used to quantify the health and density of vegitation. It is calculated from the red and near-infrared bands. The formula for NDVI is\nNDVI = NIR-Red/NIR+Red\nWhere:\n\nNIR represents the reflectance in the near-infrared spectral band.\nRed represents the reflectance in the red spectral band.\n\nNDVI values are normally between -1 to 1. Higher values indicate healthier or denser vegetation cover. In GEE calculating NDVI has its own function:\nvar NDVI_2 = clip.normalizedDifference([SR_B5, SR_B4])\nI will look at three applications of NDVI here ranging from pretty simple to very complex with increasing usefulness for policy making as you go down the list:\n1. simple GEE engine app showing NDVI for Northern Africa\n2. study using NDVI and GEE to map drought\n3. predicting famine based on NDVI.\n\n5.2.1 GEE NDVI Slider App\nThis app is a very intuitive introduction to NDVI. It is simply a base map of North Africa and South Asia with an NDVI layer. Different NDVI values are assigned 5 different colors to represent vegetation density/health. What’s cool about this app is that you can choose different times for the left and right hand side of the screen and then drag the image between them. It allows you to visually detect vegetation change. In my case here, I looked at the Nile Delta Region between 2000 and 2023. You can see that vegetation increased in the west and some of the coastal areas. What makes this app great, is that it is really simple to use and allows to communicate differences in vegetation in a very powerful way. In my case, it could help visualize the success of irrigation policy in the Nile Delta over the past two decades.\n\nknitr::include_graphics('figures/w5p3.png')\n\n\n\n\nFigure 9: NDVI Slider Application\n\n\n\n\n\nknitr::include_graphics('figures/w5p4.png')\n\n\n\n\nFigure 10: NDVI Slider Application\n\n\n\n\n\n\n5.2.2 Detecting drought\nNDVI can also be used to detect drought. Drought is one of the deadliest disasters that affect many regions of the world on a regular basis. In contrast to earth quakes or tsunamis, drought does not happen abruptly, but slowly develops overr time due to changes in the environment and climate. Monitoring these changes to alert to drought risk is therefore highly relevant in disaster risk management, e.g. to prevent famine (I will look more closely at famine in the next section.)\nKhan and Gilani (2021) developed a global Drought Severity Index (DSI) using Google Earth Engine. The study uses MODIS terra data. The parameters used to develop the index are NDVI combined with evapotranspiration (ET) and potential evapotranspiration (PET). Evapotranspiration (ET) and Potential Evapotranspiration (PET) are indicate how much water is transferred from the earth to the atmosphere through evaporation from soil and transpiration from vegetation. ET and PET data sets are in the GEE catalog from 2001 to to now. The study develops annual DSI maps using the median DSI value.\nThis study in interesting for comparing how severely different regions suffer from drough and if we can defect changes over time. However, it says nothing about the impact of drought on people.\n\nknitr::include_graphics('figures/w5p5.png')\n\n\n\n\nFigure 11: Global Drought Severity Index\n\n\n\n\n\n\n5.2.3 Predicting Famine\nThe worst impact related to drought is famine, but not every drought leads to famine. Famine, in contrast to drought however, is a man made disaster. As Alex De Waal (2017) argues, famine is driven by political conflict, embargoes and blockades, hostility against humanitarian principles and a volatile global economies or shocks. Therfore, understanding famine needs to combine data about drought with a range of other data sets on conflict, humanitarian access, population, food security, global value chains and so on.\nUSAID has been running the Famine Early Earning System Network since 1980s and is one of the major providers for evidence based early warning information on current and future food insecurity. They developed a Acute Food Insecurity Area Classification Map. They use satellite data to understand drought but enrich this with a range of other analysis including conflict, migration, market and trade\n\nknitr::include_graphics('figures/w5p6.png')\n\n\n\n\nFigure 12: Acute Food Insecurity Area Classification Map\n\n\n\n\nThis is a good example that remote sensing analysis is often most powerful for decision making when it is combined with other data sets. Its really cool that GEE allows you to do analysis at global scale and then zoom in on specific countries or regions. But the last example, shows how important it is to not overestimate the power of remote sensing. Often, it needs to be combined with other contextual data sets in order to make to most useful for e.g. planning a humanitarian response programme.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>An Introduction to Google Earth Engine</span>"
    ]
  },
  {
    "objectID": "week5.html#reflection",
    "href": "week5.html#reflection",
    "title": "5  An Introduction to Google Earth Engine",
    "section": "5.3 Reflection",
    "text": "5.3 Reflection\nGEE almost sounds a bit too good to be true, especially because it is free to use, at least for non-commercial purposes. I was curious to understand some of the issues or challenges related to GEE and had a look through the literature of this week. Some of the limitation include:\n\nLimited storage of 250GB for each user and limited memory to train machine learning algorithms.\nNo control over how computations are run in the back end, however, this is also why it is easy to use and fast.\nInteractive session limits and constraints on session duration and requests hinder flexibility. (amaniGoogleEarthEngine2020?), Gorelick et al. (2017)\n\nIn addition, to these technical issues, I could imagine that if you get started right away with GEE, you may lack some understanding of pre-processing of data and the decisions taken for corrections and enhancement, as well as the assumptions and mechanics of some of the classification models applied (more on this in the next 2 weeks). This may lead to misinterpretation of results.\nIn my view another risk related to the proliferation of remote sensing in planning practice is that it may lead to a very dominantly technocratic approach to decision making. While this is of course helpful and important, it is not the only valuable way to understand cities. Cities are complex living organisms and often best understood through different analytically lenses. Understanding the lived experience of people, cultural meaning of places and practices or political agenda is equally important to fully understand how cities work. For example, it is really useful to understand where flood risk areas are in a city, and remote sensing is a great way to do so, but it is also important to understand why people decide to settle there and perhaps reject resettlement policies, stakeholder engagement is a good way to understand this.\n\n\n\n\nAlex De Waal. 2017. Mass Starvation: The History and Future of Famine. John Wiley & Sons.\n\n\nGorelick, Noel, Matt Hancher, Mike Dixon, Simon Ilyushchenko, David Thau, and Rebecca Moore. 2017. “Google Earth Engine: Planetary-scale Geospatial Analysis for Everyone.” Remote Sensing of Environment 202 (December): 18–27. https://doi.org/10.1016/j.rse.2017.06.031.\n\n\nKhan, Ramla, and Hammad Gilani. 2021. “Global Drought Monitoring with Drought Severity Index (DSI) Using Google Earth Engine.” Theoretical and Applied Climatology 146 (1-2): 411–27. https://doi.org/10.1007/s00704-021-03715-9.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>An Introduction to Google Earth Engine</span>"
    ]
  },
  {
    "objectID": "week6.html",
    "href": "week6.html",
    "title": "6  Classification I",
    "section": "",
    "text": "6.1 Summary\nImages classification is one of the main outputs, we try to achieve when analysing satellite images. Classification turns a satellite image into a schematic map showing different land use or land cover types. Essentially, it means labeling each pixel of the selected image bands as a categorical variable.\nknitr::include_graphics('figures/w6p1.png')\n\n\n\n\nFigure 13: Classification\nThere are different types of classification that we will look at over this and next week: Classification can be",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Classification I</span>"
    ]
  },
  {
    "objectID": "week6.html#summary",
    "href": "week6.html#summary",
    "title": "6  Classification I",
    "section": "",
    "text": "supervised or unsupervised classification, and\npixel based or object-based. Object-based classification is covered next week.\n\n\n6.1.1 Supervised Classification\nIn supervised classification a predefined training data set is used where labels are known. The training data serves as a reference to train a classifier algorithm to recognize patterns in land cover or land use in the rest of the data set. Once trained it is tested on a subset of the data, the test data, to assess its accuracy. The workflow for supervised classification in GEE is broadly: \n1. Select an image.\n2. Collect training data.\n3.Select and train a classifier using the training data.\n4.Classify the image using the selected classifier.\nJeffrey A. Cardille et al. (n.d.)\nRandom Forest is a supervised machine learning algorithm used for classification and regression. It creates numerous decision trees during the training phase. Each decision tree is built using a random subset of the training data and a random subset of the input features. Each tree contributes to the final prediction of classes, and the mode or mean of these predictions is taken as the overall output. As descibed by Ha et al. (2022), its is this combination of different classification options that makes predictions robust. They explain that a random forest algorithm has four main steps:\n\nrandomly select the sample from the dataset;\nconstruction of decision trees for each sample;\nvote for the predictions;\ndetermination of the decision trees with the most votes.\n\n\nknitr::include_graphics('figures/w6p2.png')\n\n\n\n\nFigure 14: Random Forests\n\n\n\n\n\n\n6.1.2 Unsupervised Classification\nUnsupervised classification works the other way around. The classes are grouped first based on the data, using a self-taught algorithm, and then categorized into clusters. There is no reference data, where we know what category it is, in this case. The typical work flow us as follows:  \n\nAssemble features with numeric properties in which to find clusters (training data).\nSelect and instantiate a clusterer.\nTrain the clusterer with the training data.\nApply the clusterer to the scene (classification).\nLabel the clusters.\n\nJeffrey A. Cardille et al. (n.d.)",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Classification I</span>"
    ]
  },
  {
    "objectID": "week6.html#application",
    "href": "week6.html#application",
    "title": "6  Classification I",
    "section": "6.2 Application",
    "text": "6.2 Application\nThis week, I explored the application of remote sensing analysis in damage assessment in war. The damage of buildings and civil infrastructure is a specific form of violence in war, often deployed strategically, with devastating impact on civilian populations. With family members killed or injured, homes and livelihoods destroyed, commnity and public service infrastrcutre spaces damaged, people are often left with no other choice than to flee. Monitoring destruction of buildings is therefore important for understanding the dynamics of war, detecting war crimes, providing targeted humanitarian assistance and preparing for reconstruction and recovery.\nTraditionally, damage assessments are conducted through a mix of ground observation and testimony and manual visual classification from high resolution satellite images. This is cost, labor and time intensive. Current research explores (1) how to use machine learning based classification and (2) how to use publicly available data sources for detecting building damage in conflict zones to offer approaches that are faster, more accessible and simplementable at scale. One of the key methodological challenges is that classes (no damage vs damage) are really unbalanced because even after intense attacks, only very few show damage even after a large scale attack and that destruction occurs over time. (“Monitoring War Destruction from Space Using Machine Learning” n.d.)\nLet’s look at two recent studies from Syria and Ukraine.\n\n6.2.1 Damage Assessment in Syria using machine learning\n“Monitoring War Destruction from Space Using Machine Learning” (n.d.) use high resolution data of three Syrian cities and applies machine learning technique to detect building damage over time. They use a two stage classification process which feeds data first to a Convolutional Neural Networks (CNN) and then passes it through a random forest. To get a rough understanding of CNN, watch the video linked below. The CNN generates labels and predicted values for each pixel that are then used to train a RF model to generate a prediction for the test sample. The two steps are needed because building damage is both spatially as well as structurally auto-correlated and hence using just a RF would lead to over fitting of the model. While this approach is techncially quite complex, it is very useful because the machine learning approach makes it applicable in conflict regions anywhere and scaling it doesnt come with significant extra costs.\n\n\n&lt;iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/vJiZqZRkIg8\" frameborder=\"0\" allowfullscreen&gt;&lt;/iframe&gt;\n\n\n\nknitr::include_graphics('figures/w6p3.png')\n\n\n\n\nFigure 15: Damange Assessment Allepo\n\n\n\n\n\n\n6.2.2 Damage Assessment in Ukraine using public data sources\nAimaiti et al. (2022) use a completely different approach for detecting buidling distruction in Kyiv Ukraine. The focus of their methodology is on testing how useful publicly available sattelite data can be for damage assessment.\nThe study tests two different approaches: 1. Sentinel 1 data applying a SAR log ratio of intensity (SAR = Synthetic Aperture Radar is a remote sensing technology that uses microwave radar to create high-resolution images of the Earth’s surface, regardless of weather conditions or time of day.) 2. Sentinel 2 data applying texture analysis\nTo support this approach, changes in other other land covers (e.g., forest) are suppresed using a mask for buit up areas based on OpenStreetMap building footprints and World Settlement Footprint (WSF). For assessing the accuracy of the approach the classification was manually verified by comparing findings with the official United Nations Satellite Center (UNOSAT) damage assessment map. The classification (combined from the two appriaches) achieved accuracy of 58%.\n\nknitr::include_graphics('figures/w6p4.png')\n\n\n\n\nFigure 16: Damange Assessment Kyiv\n\n\n\n\nThis approach is useful, because it provides a low cost methodology for damage assessment. However, the accuracy rate is not very confincing. This approach may be useful for an initial rapid assessment. It is less useful as a baseline for planning humanitarian programmes, military action or reconstruction.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Classification I</span>"
    ]
  },
  {
    "objectID": "week6.html#reflection",
    "href": "week6.html#reflection",
    "title": "6  Classification I",
    "section": "6.3 Reflection",
    "text": "6.3 Reflection\nThis week was really facinating!\nFirst, it’s been great to start looking into machine learning and starting to grasp how classification works methodologically.\nSecondly, I really enjoyed looking into the application area of conflict monitoring. I have previously conducted reserach in this field from a social science perspective. I looked at urban development in the West Bank and Refugee Housing in Berlin both from the perspective of critical theory and post colonial research. While it was brilliant to deeply understand these phenomena through theory, I always felt like my research was missing evidence and applicability in policy making. The studies discussed above are highly relevant for practicioners and provide a more objective evidence base for understanding war.\nTwo thinks struck me while digesting the studies discussed above: 1. Neither of them mentions Google Earth Engine, which supprised me. After last weeks lecture, I got the impression that nearly all studies now use GEE. I wonder why they chose not to use it here. 2. Both studies confirmed, again, the need to enrich remote sensing data with other contextual data sources.This seems to be emerging as a key learning from engaging with literature on very different use cases.\n\n\n\n\nAimaiti, Yusupujiang, Christina Sanon, Magaly Koch, Laurie G. Baise, and Babak Moaveni. 2022. “War Related Building Damage Assessment in Kyiv, Ukraine, Using Sentinel-1 Radar and Sentinel-2 Optical Images.” Remote Sensing 14 (24): 6239. https://doi.org/10.3390/rs14246239.\n\n\nHa, Minh, Phuong Vu, Huu Nguyen, Tich Hoang, Dinh Dang, Thi Dinh, Gheorghe Şerban, Ioan Rus, and Petre Brețcan. 2022. “Machine Learning and Remote Sensing Application for Extreme Climate Evaluation: Example of Flood Susceptibility in the Hue Province, Central Vietnam Region.” Water 14 (10): 1617. https://doi.org/10.3390/w14101617.\n\n\nJeffrey A. Cardille, Nick Clinton, Morgan Crowley, and David Saah. n.d. Cloud-Based Remote Sensing with Google Earth Engine. https://www.eefabook.org/about.html.\n\n\n“Monitoring War Destruction from Space Using Machine Learning.” n.d. Accessed March 9, 2024. https://doi.org/10.1073/pnas.2025400118.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Classification I</span>"
    ]
  }
]