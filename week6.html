<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.4.549">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>week6</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="week6_files/libs/clipboard/clipboard.min.js"></script>
<script src="week6_files/libs/quarto-html/quarto.js"></script>
<script src="week6_files/libs/quarto-html/popper.min.js"></script>
<script src="week6_files/libs/quarto-html/tippy.umd.min.js"></script>
<script src="week6_files/libs/quarto-html/anchor.min.js"></script>
<link href="week6_files/libs/quarto-html/tippy.css" rel="stylesheet">
<link href="week6_files/libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="week6_files/libs/bootstrap/bootstrap.min.js"></script>
<link href="week6_files/libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="week6_files/libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">


</head>

<body class="fullcontent">

<div id="quarto-content" class="page-columns page-rows-contents page-layout-article">

<main class="content" id="quarto-document-content">




<section id="classification-i" class="level1">
<h1>Classification I</h1>
<section id="summary" class="level2">
<h2 class="anchored" data-anchor-id="summary">Summary</h2>
<p>Images classification is one of the main outputs, we try to achieve when analysing satellite images. Classification turns a satellite image into a schematic map showing different land use or land cover types. Essentially, it means labeling each pixel of the selected image bands as a categorical variable.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a>knitr<span class="sc">::</span><span class="fu">include_graphics</span>(<span class="st">'figures/w6p1.png'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="figures/w6p1.png" class="img-fluid figure-img" style="width:100.0%"></p>
<figcaption>Figure 13: Classification</figcaption>
</figure>
</div>
</div>
</div>
<p>There are different types of classification that we will look at over this and next week: Classification can be</p>
<ul>
<li><p>supervised or unsupervised classification, and</p></li>
<li><p>pixel based or object-based. Object-based classification is covered next week.</p></li>
</ul>
<section id="supervised-classification" class="level3">
<h3 class="anchored" data-anchor-id="supervised-classification">Supervised Classification</h3>
<p>In supervised classification a predefined training data set is used where labels are known. The training data serves as a reference to train a classifier algorithm to recognize patterns in land cover or land use in the rest of the data set. Once trained it is tested on a subset of the data, the test data, to assess its accuracy. The workflow for supervised classification in GEE is broadly:&nbsp;</p>
<p>1. Select an image.</p>
<p>2. Collect training data.</p>
<p>3.Select and train a classifier using the training data.</p>
<p>4.Classify the image using the selected classifier.</p>
<p><span class="citation" data-cites="jeffreya.cardilleCloudBasedRemoteSensing">@jeffreya.cardilleCloudBasedRemoteSensing</span></p>
<p>Random Forest is a supervised machine learning algorithm used for classification and regression. It creates numerous decision trees during the training phase. Each decision tree is built using a random subset of the training data and a random subset of the input features. Each tree contributes to the final prediction of classes, and the mode or mean of these predictions is taken as the overall output. As descibed by <span class="citation" data-cites="haMachineLearningRemote2022">@haMachineLearningRemote2022</span>, its is this combination of different classification options that makes predictions robust. They explain that a random forest algorithm has four main steps:</p>
<ol type="1">
<li><p>randomly select the sample from the dataset;</p></li>
<li><p>construction of decision trees for each sample;</p></li>
<li><p>vote for the predictions;</p></li>
<li><p>determination of the decision trees with the most votes.</p></li>
</ol>
<div class="cell">
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a>knitr<span class="sc">::</span><span class="fu">include_graphics</span>(<span class="st">'figures/w6p2.png'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="figures/w6p2.png" class="img-fluid figure-img" style="width:100.0%"></p>
<figcaption>Figure 14: Random Forests</figcaption>
</figure>
</div>
</div>
</div>
</section>
<section id="unsupervised-classification" class="level3">
<h3 class="anchored" data-anchor-id="unsupervised-classification">Unsupervised Classification</h3>
<p>Unsupervised classification works the other way around. The classes are grouped first based on the data, using a self-taught algorithm, and then categorized into clusters. There is no reference data, where we know what category it is, in this case. The typical work flow us as follows: &nbsp;</p>
<ol type="1">
<li><p>Assemble features with numeric properties in which to find clusters (training data).</p></li>
<li><p>Select and instantiate a clusterer.</p></li>
<li><p>Train the clusterer with the training data.</p></li>
<li><p>Apply the clusterer to the scene (classification).</p></li>
<li><p>Label the clusters.</p></li>
</ol>
<p><span class="citation" data-cites="jeffreya.cardilleCloudBasedRemoteSensing">@jeffreya.cardilleCloudBasedRemoteSensing</span></p>
</section>
</section>
<section id="application" class="level2">
<h2 class="anchored" data-anchor-id="application">Application</h2>
<p>This week, I explored the application of remote sensing analysis in damage assessment in war. The damage of buildings and civil infrastructure is a specific form of violence in war, often deployed strategically, with devastating impact on civilian populations. With family members killed or injured, homes and livelihoods destroyed, commnity and public service infrastrcutre spaces damaged, people are often left with no other choice than to flee. Monitoring destruction of buildings is therefore important for understanding the dynamics of war, detecting war crimes, providing targeted humanitarian assistance and preparing for reconstruction and recovery.</p>
<p>Traditionally, damage assessments are conducted through a mix of ground observation and testimony and manual visual classification from high resolution satellite images. This is cost, labor and time intensive. Current research explores (1) how to use machine learning based classification and (2) how to use publicly available data sources for detecting building damage in conflict zones to offer approaches that are faster, more accessible and simplementable at scale. One of the key methodological challenges is that classes (no damage vs damage) are really unbalanced because even after intense attacks, only very few show damage even after a large scale attack and that destruction occurs over time. <span class="citation" data-cites="MonitoringWarDestructiona">[@MonitoringWarDestructiona]</span></p>
<p>Let’s look at two recent studies from Syria and Ukraine.</p>
<section id="damage-assessment-in-syria-using-machine-learning" class="level3">
<h3 class="anchored" data-anchor-id="damage-assessment-in-syria-using-machine-learning">Damage Assessment in Syria using machine learning</h3>
<p><span class="citation" data-cites="MonitoringWarDestructiona">@MonitoringWarDestructiona</span> use high resolution data of three Syrian cities and applies machine learning technique to detect building damage over time. They use a two stage classification process which feeds data first to a Convolutional Neural Networks (CNN) and then passes it through a random forest. To get a rough understanding of CNN, watch the video linked below. The CNN generates labels and predicted values for each pixel that are then used to train a RF model to generate a prediction for the test sample. The two steps are needed because building damage is both spatially as well as structurally auto-correlated and hence using just a RF would lead to over fitting of the model. While this approach is techncially quite complex, it is very useful because the machine learning approach makes it applicable in conflict regions anywhere and scaling it doesnt come with significant extra costs.</p>
<div class="cell">
<div class="cell-output cell-output-stdout">
<pre><code>&lt;iframe width="560" height="315" src="https://www.youtube.com/embed/vJiZqZRkIg8" frameborder="0" allowfullscreen&gt;&lt;/iframe&gt;</code></pre>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a>knitr<span class="sc">::</span><span class="fu">include_graphics</span>(<span class="st">'figures/w6p3.png'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="figures/w6p3.png" class="img-fluid figure-img" style="width:100.0%"></p>
<figcaption>Figure 15: Damange Assessment Allepo</figcaption>
</figure>
</div>
</div>
</div>
</section>
<section id="damage-assessment-in-ukraine-using-public-data-sources" class="level3">
<h3 class="anchored" data-anchor-id="damage-assessment-in-ukraine-using-public-data-sources">Damage Assessment in Ukraine using public data sources</h3>
<p><span class="citation" data-cites="aimaitiWarRelatedBuilding2022">@aimaitiWarRelatedBuilding2022</span> use a completely different approach for detecting buidling distruction in Kyiv Ukraine. The focus of their methodology is on testing how useful publicly available sattelite data can be for damage assessment.</p>
<p>The study tests two different approaches: 1. Sentinel 1 data applying a SAR log ratio of intensity (SAR = Synthetic Aperture Radar is a remote sensing technology that uses microwave radar to create high-resolution images of the Earth’s surface, regardless of weather conditions or time of day.) 2. Sentinel 2 data applying texture analysis</p>
<p>To support this approach, changes in other other land covers (e.g., forest) are suppresed using a mask for buit up areas based on OpenStreetMap building footprints and World Settlement Footprint (WSF). For assessing the accuracy of the approach the classification was manually verified by comparing findings with the official United Nations Satellite Center (UNOSAT) damage assessment map. The classification (combined from the two appriaches) achieved accuracy of 58%.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a>knitr<span class="sc">::</span><span class="fu">include_graphics</span>(<span class="st">'figures/w6p4.png'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="figures/w6p4.png" class="img-fluid figure-img" style="width:100.0%"></p>
<figcaption>Figure 16: Damange Assessment Kyiv</figcaption>
</figure>
</div>
</div>
</div>
<p>This approach is useful, because it provides a low cost methodology for damage assessment. However, the accuracy rate is not very confincing. This approach may be useful for an initial rapid assessment. It is less useful as a baseline for planning humanitarian programmes, military action or reconstruction.</p>
</section>
</section>
<section id="reflection" class="level2">
<h2 class="anchored" data-anchor-id="reflection">Reflection</h2>
<p>This week was really facinating!</p>
<p>First, it’s been great to start looking into machine learning and starting to grasp how classification works methodologically.</p>
<p>Secondly, I really enjoyed looking into the application area of conflict monitoring. I have previously conducted reserach in this field from a social science perspective. I looked at urban development in the West Bank and Refugee Housing in Berlin both from the perspective of critical theory and post colonial research. While it was brilliant to deeply understand these phenomena through theory, I always felt like my research was missing evidence and applicability in policy making. The studies discussed above are highly relevant for practicioners and provide a more objective evidence base for understanding war.</p>
<p>Two thinks struck me while digesting the studies discussed above: 1. Neither of them mentions Google Earth Engine, which supprised me. After last weeks lecture, I got the impression that nearly all studies now use GEE. I wonder why they chose not to use it here. 2. Both studies confirmed, again, the need to enrich remote sensing data with other contextual data sources.This seems to be emerging as a key learning from engaging with literature on very different use cases.</p>
</section>
</section>

</main>
<!-- /main column -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      // TODO in 1.5, we should make sure this works without a callout special case
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->




</body></html>